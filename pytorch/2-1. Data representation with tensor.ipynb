{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "modified-walter",
   "metadata": {},
   "source": [
    "![torchman](imgs/torchman.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-alpha",
   "metadata": {},
   "source": [
    "이번 차례에는 머신러닝 파이프라인을 살펴보고 데이터를 어떻게 텐서를 통해 표현하는지 살펴보겠습니다  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-berry",
   "metadata": {},
   "source": [
    "# Deep learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-information",
   "metadata": {},
   "source": [
    "![dlpl](imgs/pipelin.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "respective-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-student",
   "metadata": {},
   "source": [
    "저희가 지금까지 배운 수 체계에는 스칼라, 벡터, 행렬, 텐서가 있었습니다.  \n",
    "그리고 많은 머신러닝 책에서는 아래와 같이 표기합니다.  \n",
    "여러 모듈과 메소드를 통해 파이토치에서 어떻게 텐서를 조작하는지 알아보겠습니다  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-history",
   "metadata": {},
   "source": [
    "$${스칼라 : x\\quad 0 \\ (0차원) \\\\ \n",
    "벡터 : \\mathbf x \\quad n \\ (1차원) \\\\ \n",
    "행렬 : \\mathbf X \\quad m \\times n \\ (2차원) \\\\\n",
    "텐서 : \\mathcal {X} \\quad l \\times m \\times n \\times \\dots \\  (3차원 이상) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-antibody",
   "metadata": {},
   "source": [
    "먼저 들어가기 앞서서 프로그래밍 초반에 배우는 데이터의 타입을 떠올려보겠습니다.  \n",
    "대표적으로 다음과 같습니다. \n",
    "1. Int  \n",
    "2. Double  \n",
    "3. Float  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-object",
   "metadata": {},
   "source": [
    "일반적으로 torch의 여러가지 텐서모듈을 통해 위의 데이터타입을 가지는 텐서를 생성할 수 있습니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "central-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from torch import FloatTensor as ftensor\n",
    "from torch import DoubleTensor as dtensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-slave",
   "metadata": {},
   "source": [
    "텐서 객체는 다음과 같은 형태로 할당하게 됩니다.  \n",
    "tensor = tensor(data, dtype=float32, device='cpu')  \n",
    "텐서 객체를 생성하기 위한 파라미터와 인자는 data, dtype, device가 있습니다.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-porter",
   "metadata": {},
   "source": [
    "## 1. 스칼라"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-inclusion",
   "metadata": {},
   "source": [
    "dtype과 device를 지정하지 않으면 자동으로 dtype을 식별하고 device는 cpu로 할당하게 됩니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nonprofit-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "torch.int64\n",
      "cpu\n",
      "tensor(99.9900, dtype=torch.float64)\n",
      "torch.float64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "scalar = tensor(3)\n",
    "print(scalar)\n",
    "print(scalar.dtype)\n",
    "print(scalar.device)\n",
    "\n",
    "scalar2 = tensor(99.99, dtype=float)\n",
    "print(scalar2)\n",
    "print(scalar2.dtype)\n",
    "print(scalar2.device)\n",
    "\n",
    "# 텐서 오브젝트의 dtype와 device는 모두 통일시켜야 한다!\n",
    "# 즉, 입력 인풋의 데이터 타입과 모델 가중치의 데이터 타입이 같아야 한다.\n",
    "# 또한, 입력 인풋과 모델 가중치의 계산장치가 같아야 한다.\n",
    "# 위 둘은 필수로 생각해두자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-third",
   "metadata": {},
   "source": [
    ".item()을 통하여 텐서 객체 내의 단일 스칼라 값을 뽑아낼 수 있습니다. item 메소드는 반드시 스칼라 텐서에서 호출해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comfortable-weekend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99\n"
     ]
    }
   ],
   "source": [
    "print(scalar2.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-consortium",
   "metadata": {},
   "source": [
    "## 2. 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electrical-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exclusive-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# 벡터, 텐서\n",
    "# numpy에서는 시퀀스 데이터(리스트, 튜플)을 넣어서 벡터나 텐서를 표현함\n",
    "vec = np.array([1, 2, 3, 4])\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-ranking",
   "metadata": {},
   "source": [
    "data에 들어갈 수 있는 컨테이너는 List, Tuple, Numpy array입니다.  \n",
    "파이토치에서 텐서 객체를 만드는 방법은 기존의 numpy와 매우 유사합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compliant-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0000, -1.1000,  3.9000])\n",
      "torch.float32\n",
      "tensor([ 1.0000, -1.1000,  3.9000], dtype=torch.float64)\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([ 1, -1,  3])\n"
     ]
    }
   ],
   "source": [
    "vec1 = ftensor([1.0, -1.1, 3.9]) # list input\n",
    "vec2 = dtensor([1.0, -1.1, 3.9]) # Tuple data\n",
    "vec3 = tensor(np.array([1, 2, 3, 4])) # numpy array input\n",
    "vec4 = tensor([1.0, -1.1, 3.9], dtype=int)\n",
    "print(vec1)\n",
    "print(vec1.dtype)\n",
    "print(vec2)\n",
    "print(vec3)\n",
    "print(vec4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-effects",
   "metadata": {},
   "source": [
    "## 3. 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-attempt",
   "metadata": {},
   "source": [
    "이제 행렬 텐서를 만들어보겠습니다.  \n",
    "데이터타입을 행렬로 다루기 시작한다면 device를 gpu로 지정하는게 좋습니다.  \n",
    "이제 데이터를 일일히 생성하기 힘드므로 rand를 사용하겠습니다.  \n",
    "rand를 잘 활용하기 위해 시드를 고정하겠습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "republican-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8903, 0.0275],\n",
      "        [0.9031, 0.5386]], device='cuda:0')\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(1) # torch.manual_seed(seed) 랜덤 생성 시드를 seed로 고정\n",
    "mat = th.rand([2,2], device='cuda:0')\n",
    "# mat = th.rand([2,2], device='cpu')\n",
    "\n",
    "print(mat)\n",
    "print(mat.device)\n",
    "\n",
    "\n",
    "# 라인에서 ctrl +c 복사\n",
    "# ctrl + shift + left 단어선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-royalty",
   "metadata": {},
   "source": [
    "![tensor](imgs/tensor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-vegetable",
   "metadata": {},
   "source": [
    "## 4. 텐서  \n",
    "이제 3차원 이상의 텐서를 만들어보겠습니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "central-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[108, 212,  86],\n",
      "         [175, 145, 170],\n",
      "         [ 10, 227, 245],\n",
      "         ...,\n",
      "         [188,   0,  30],\n",
      "         [207,  70,  78],\n",
      "         [144, 123,  50]],\n",
      "\n",
      "        [[218, 141, 185],\n",
      "         [141, 183, 114],\n",
      "         [ 52, 164, 160],\n",
      "         ...,\n",
      "         [129, 183, 105],\n",
      "         [234,  67, 211],\n",
      "         [ 67,  81, 203]],\n",
      "\n",
      "        [[ 15, 179,  43],\n",
      "         [114,  60, 197],\n",
      "         [148, 126,  65],\n",
      "         ...,\n",
      "         [ 68, 232,  22],\n",
      "         [ 16, 235, 169],\n",
      "         [ 75,  30, 199]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[207,  32, 185],\n",
      "         [212,  29,  94],\n",
      "         [ 80, 243,  27],\n",
      "         ...,\n",
      "         [139, 243,  87],\n",
      "         [ 88, 131, 156],\n",
      "         [  1, 125,  34]],\n",
      "\n",
      "        [[183, 243, 178],\n",
      "         [100, 254,  53],\n",
      "         [212, 115, 209],\n",
      "         ...,\n",
      "         [150, 250, 103],\n",
      "         [106, 128, 136],\n",
      "         [158, 247, 110]],\n",
      "\n",
      "        [[109,  54, 248],\n",
      "         [215, 170, 121],\n",
      "         [156, 129, 136],\n",
      "         ...,\n",
      "         [154,  60, 107],\n",
      "         [126,  36, 138],\n",
      "         [ 41,  65, 146]]], device='cuda:0')\n",
      "torch.int64\n",
      "tensor([[[108, 212,  86],\n",
      "         [175, 145, 170],\n",
      "         [ 10, 227, 245],\n",
      "         ...,\n",
      "         [188,   0,  30],\n",
      "         [207,  70,  78],\n",
      "         [144, 123,  50]],\n",
      "\n",
      "        [[218, 141, 185],\n",
      "         [141, 183, 114],\n",
      "         [ 52, 164, 160],\n",
      "         ...,\n",
      "         [129, 183, 105],\n",
      "         [234,  67, 211],\n",
      "         [ 67,  81, 203]],\n",
      "\n",
      "        [[ 15, 179,  43],\n",
      "         [114,  60, 197],\n",
      "         [148, 126,  65],\n",
      "         ...,\n",
      "         [ 68, 232,  22],\n",
      "         [ 16, 235, 169],\n",
      "         [ 75,  30, 199]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[207,  32, 185],\n",
      "         [212,  29,  94],\n",
      "         [ 80, 243,  27],\n",
      "         ...,\n",
      "         [139, 243,  87],\n",
      "         [ 88, 131, 156],\n",
      "         [  1, 125,  34]],\n",
      "\n",
      "        [[183, 243, 178],\n",
      "         [100, 254,  53],\n",
      "         [212, 115, 209],\n",
      "         ...,\n",
      "         [150, 250, 103],\n",
      "         [106, 128, 136],\n",
      "         [158, 247, 110]],\n",
      "\n",
      "        [[109,  54, 248],\n",
      "         [215, 170, 121],\n",
      "         [156, 129, 136],\n",
      "         ...,\n",
      "         [154,  60, 107],\n",
      "         [126,  36, 138],\n",
      "         [ 41,  65, 146]]])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(2)\n",
    "T = th.rand([64,64,3], device = 'cuda:0')\n",
    "# T = th.rand([64,64,3], device = 'cpu')\n",
    "T = T * 256\n",
    "# to() : 텐서 내의 메소드로 원하는 데이터 타입, 원하는 디바이스의 텐서를 반환\n",
    "T = T.to(int)\n",
    "print(T)\n",
    "print(T.dtype)\n",
    "\n",
    "\n",
    "T = T.to('cpu')\n",
    "print(T)\n",
    "print(T.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-feeling",
   "metadata": {},
   "source": [
    "# 퀴즈 (Easy)  \n",
    "1) !nvidia-smi 를 통해 현재 gpu의 메모리 사용량을 확인하세요\n",
    "2) 크기가 (100, 100, 100)인 3차원 랜덤 텐서를 gpu 메모리에 할당하세요\n",
    "3) 다시 !nvidia-smi를 통해 gpu 메모리 사용량이 얼마나 늘었는지 계산해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "expired-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 29 05:15:52 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   62C    P0    72W / 149W |    494MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "effective-gentleman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "th.manual_seed(2)\n",
    "T = th.rand([100, 100, 100], device = 'cuda:0')\n",
    "\n",
    "# quiz : 리스트 컴프리헨션으로 100개의 텐서를 리스트에 넣으세요\n",
    "a = [T for _ in range(100)]\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acquired-florida",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 29 05:26:03 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   62C    P0    72W / 149W |    514MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
