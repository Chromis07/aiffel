{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, '<PAD>'), (1, '<BOS>'), (2, '<UNK>'), (3, 'i'), (4, 'feel'), (5, 'hungry'), (6, 'eat'), (7, 'lunch'), (8, 'now'), (9, 'happy')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word \n",
    "                                     in word_to_index \n",
    "                                     else word_to_index['<UNK>'] \n",
    "                                     for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) \n",
    "            for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index \n",
    "                    in index_to_word else '<UNK>' \n",
    "                    for index \n",
    "                    in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) \n",
    "            for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩 레이어   \n",
    "https://wikidocs.net/64779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10940/2643569513.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m     if any(isinstance(x, (\n\u001b[0;32m    959\u001b[0m         np_arrays.ndarray, np.ndarray, float, int)) for x in input_list):\n\u001b[1;32m--> 960\u001b[1;33m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    961\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   3307\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3308\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp_arrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3309\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3310\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1403\u001b[0m   \"\"\"\n\u001b[0;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[1;32m-> 1405\u001b[1;33m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[0;32m   1406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1540\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 265\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py37\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "\n",
    "# 인풋 문장 벡터는 길이가 일정해야한다.\n",
    "# 위 raw_inputs의 벡터 길이는 각각 4, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences\n",
    "# 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능\n",
    "\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "\n",
    "# 짧은 문장은 뒤에 0으로 채워짐 (<PAD>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.03342279  0.02345349  0.02083625  0.00064234]\n",
      "  [-0.02150408  0.04946489 -0.00511415 -0.04200254]\n",
      "  [ 0.0311246  -0.0358973  -0.00822328 -0.02372218]\n",
      "  [-0.006004    0.01264485  0.02771846 -0.03763587]\n",
      "  [-0.01289556  0.02739314 -0.02443199 -0.02730279]]\n",
      "\n",
      " [[-0.03342279  0.02345349  0.02083625  0.00064234]\n",
      "  [-0.02150408  0.04946489 -0.00511415 -0.04200254]\n",
      "  [ 0.03674347 -0.03774816 -0.03378655  0.00875385]\n",
      "  [-0.02154994  0.03889073  0.0101529  -0.00946436]\n",
      "  [-0.01289556  0.02739314 -0.02443199 -0.02730279]]\n",
      "\n",
      " [[-0.03342279  0.02345349  0.02083625  0.00064234]\n",
      "  [-0.02065876  0.03909311  0.0128047  -0.03172054]\n",
      "  [-0.02150408  0.04946489 -0.00511415 -0.04200254]\n",
      "  [ 0.0311246  -0.0358973  -0.00822328 -0.02372218]\n",
      "  [ 0.02175704  0.0002513  -0.01301225 -0.04534277]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)\n",
    "\n",
    "# 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D Convolution Neural Network(1-D CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobalMaxPooling1D() 레이어 하나만 사용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 해볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB 영화리뷰 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '\n",
    "      .format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 됩니다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적입니다. 따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 직접 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 31ms/step - loss: 0.6921 - accuracy: 0.5123 - val_loss: 0.6886 - val_accuracy: 0.6198\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.6861 - accuracy: 0.7206 - val_loss: 0.6797 - val_accuracy: 0.7797\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6745 - accuracy: 0.8106 - val_loss: 0.6639 - val_accuracy: 0.7945\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.6541 - accuracy: 0.8246 - val_loss: 0.6373 - val_accuracy: 0.8079\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.6201 - accuracy: 0.8432 - val_loss: 0.5955 - val_accuracy: 0.8158\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5699 - accuracy: 0.8527 - val_loss: 0.5465 - val_accuracy: 0.8244\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.5136 - accuracy: 0.8635 - val_loss: 0.4958 - val_accuracy: 0.8300\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.4529 - accuracy: 0.8675 - val_loss: 0.4478 - val_accuracy: 0.8366\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3963 - accuracy: 0.8773 - val_loss: 0.4082 - val_accuracy: 0.8416\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.3469 - accuracy: 0.8840 - val_loss: 0.3789 - val_accuracy: 0.8455\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.3056 - accuracy: 0.8958 - val_loss: 0.3609 - val_accuracy: 0.8489\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2765 - accuracy: 0.9059 - val_loss: 0.3497 - val_accuracy: 0.8500\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.2539 - accuracy: 0.9094 - val_loss: 0.3421 - val_accuracy: 0.8530\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2353 - accuracy: 0.9196 - val_loss: 0.3372 - val_accuracy: 0.8540\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2173 - accuracy: 0.9262 - val_loss: 0.3345 - val_accuracy: 0.8533\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.2064 - accuracy: 0.9271 - val_loss: 0.3336 - val_accuracy: 0.8544\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 0.1856 - accuracy: 0.9386 - val_loss: 0.3332 - val_accuracy: 0.8558\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 0.1719 - accuracy: 0.9421 - val_loss: 0.3344 - val_accuracy: 0.8554\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1614 - accuracy: 0.9475 - val_loss: 0.3362 - val_accuracy: 0.8554\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.1508 - accuracy: 0.9531 - val_loss: 0.3383 - val_accuracy: 0.8555\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3657 - accuracy: 0.8426\n",
      "[0.36571890115737915, 0.8425599932670593]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = './data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w',encoding='UTF-8') # 로컬에선 인코딩 UTF-8 필수\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03390543, -0.02708206, -0.01569388, -0.04209021, -0.02751395,\n",
       "       -0.03629457, -0.03754557, -0.04741062, -0.02427924, -0.0249802 ,\n",
       "       -0.02734087, -0.03647846, -0.02046586, -0.02900488,  0.15035975,\n",
       "       -0.02334145], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('just', 0.9921589493751526),\n",
       " ('nature', 0.9914568066596985),\n",
       " ('channel', 0.9908318519592285),\n",
       " ('plays', 0.990032434463501),\n",
       " ('violent', 0.9889442324638367),\n",
       " ('every', 0.9885019659996033),\n",
       " ('join', 0.9884850978851318),\n",
       " ('wife', 0.9874370098114014),\n",
       " (\"won't\", 0.9873944520950317),\n",
       " ('meet', 0.987138569355011)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ratsgo.github.io/natural%20language%20processing/2019/09/12/embedding/   \n",
    "한국어 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_10940/2379628378.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Chromis\\AppData\\Local\\Temp/ipykernel_10940/2379628378.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    brew install wget\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7b26eb2611282d90d9c5c5eb5497dd9fe754f45e0da87815f2566e1ffecfffe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('py37': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
