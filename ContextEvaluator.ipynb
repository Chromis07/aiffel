{"cells":[{"cell_type":"markdown","id":"spare-fraction","metadata":{"id":"spare-fraction"},"source":["## ContextEvaluator"]},{"cell_type":"code","execution_count":1,"id":"maritime-paintball","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"elapsed":6095,"status":"error","timestamp":1642641398736,"user":{"displayName":"박장호","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13072686141127167034"},"user_tz":-540},"id":"maritime-paintball","outputId":"58f81048-f252-4f93-825f-821383bfaf96"},"outputs":[],"source":["import torch\n","import numpy as np\n","from transformers import BertTokenizer, BertForNextSentencePrediction\n","\n","class ContextEvaluator:\n","    def __init__(self, nsp_limit):\n","        self.nsp_limit = nsp_limit\n","        self.tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n","        self.model = BertForNextSentencePrediction.from_pretrained('klue/bert-base')\n","        \n","    def evaluate_context(self, text1, text2):\n","        #0: IsNSP, 1: NotNSP\n","        \n","        def cal_softmax(x):\n","            #get_softmax value\n","            softmax_x = np.exp(x - np.max(x))\n","            return softmax_x / softmax_x.sum()\n","        \n","        input_tensor = self.tokenizer(text1, text2, return_tensors='pt')\n","        predict = self.model(**input_tensor)\n","        predict = predict.logits.detach().numpy()[0]   #tensor2numpy\n","        \n","        softmax = cal_softmax(predict)\n","        return softmax[0]   #softmax[0] == IsNSP probability"]},{"cell_type":"code","execution_count":2,"id":"leading-radical","metadata":{"id":"leading-radical","outputId":"1323ef8d-2cf2-45fd-de2f-ab5117f266fe"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcc806fb22e642acb4333646adf856f5","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b00f3940e4bf45fbad5e00eeab17ce9b","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fffaa1b0ad4e4c47972b1b76f1ab3781","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"254eccf0e1234967992a201c641c2caa","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/483k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df81b8ed38f841b2b84899638ca2f904","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"382e73e28dfb4c2396ff78105a28ee87","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["#Load Class\n","contextEvaluator = ContextEvaluator(0.5)"]},{"cell_type":"markdown","id":"collaborative-graham","metadata":{"id":"collaborative-graham"},"source":["## Test"]},{"cell_type":"code","execution_count":18,"id":"official-clarity","metadata":{"id":"official-clarity","outputId":"f88ff799-e3a6-41e1-8024-d9530df8b4cc"},"outputs":[{"data":{"text/plain":["0.34925595"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["contextEvaluator.evaluate_context(\"오늘은 뭐 먹고 왔어?\", \"너무 춥다\")"]},{"cell_type":"code","execution_count":null,"id":"751b1ae4","metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"ContextEvaluator.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":5}
